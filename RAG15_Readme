RAG Fusion Pipeline Summary (LangChain Style)
RAG Fusion improves document retrieval by generating multiple query variations from the user's original question.

The pipeline is constructed using LangChain Expression Language (LCEL) chaining syntax with the | operator.

generate_queries: A component (like an LLM chain) that outputs multiple reformulations of the input query.

Example:

vbnet
Copy
Edit
Input: "What is RAG?"
Output: ["Explain RAG", "What is Retrieval-Augmented Generation?", "How does RAG work?"]
retriever.map(): Applies the retriever (like Chroma or FAISS) to each of those queries and returns top-k documents per query.

Result: A list of ranked document lists, one for each query.

reciprocal_rank_fusion (RRF): Merges all those ranked lists into a single final ranked document list.

RRF assigns scores using 1 / (rank + k) — rewarding documents that appear early and frequently.

This fusion improves relevance and recall by combining signals from all query variants.

The full chain:

python
Copy
Edit
retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion
You can call the chain like this:

python
Copy
Edit
results = retrieval_chain_rag_fusion.invoke("What is RAG?")
Output: A single, fused, and sorted list of relevant documents — ideal for generation.

Benefits:

Handles query ambiguity better

Boosts recall and diversity

Easy to compose and extend

Optional: You can plug this into an LLM for final answer generation (e.g., using a local model like phi-4).

Works best when retriever.map() returns top-k (e.g., 3–5) results per query, not just 1.

